
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>

<link rel="stylesheet" type="text/css" href="style.css" />
  

<!-- End : Google Analytics Code -->
<script type="text/javascript" src="../js/hidebib.js"></script>
<!-- <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'> -->
<!-- <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,300,300italic,400italic,600,600italic,700,700italic,800,800italic' rel='stylesheet' type='text/css'> -->
<link href='https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro' rel='stylesheet' type='text/css'>
  
<head>
    <title>GANHead: Towards Generative Animatable Neural Head Avatars</title>
    <meta property="og:description" content="GANHead: Towards Generative Animatable Neural Head Avatars"/>
    <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-6HHDEXF452"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-6HHDEXF452');
</script>

</head>


 <body>
<div class="container">
    <div class="paper-title">
      <h1>GANHead: Towards Generative Animatable Neural Head Avatars</h1>
    </div>
  

    
    <div id="authors">
        <div class="author-row">
            <div class="col-8 text-center">Sijing Wu<sup>1</sup></div>
            <div class="col-8 text-center"><a href="https://daodaofr.github.io/">Yichao Yan</a><sup>1</sup></div>
            <div class="col-8 text-center">Yunhao Li<sup>1</sup></div>
            <div class="col-8 text-center">Yuhao Cheng<sup>1</sup></div>
            <div class="col-8 text-center">Wenhan Zhu<sup>1</sup></div>
            <div class="col-8 text-center">Ke Gao<sup>2</sup></div>
            <div class="col-8 text-center">XiaoBo Li<sup>2</sup></div>
            <div class="col-8 text-center"><a href="https://scholar.google.com/citations?user=E6zbSYgAAAAJ&hl=en&oi=ao">Guangtao Zhai</a><sup>1</sup></div>
        </div>

<!--         <div class="affil-row">
            <div class="col-2 text-center"><sup>1</sup><a href="https://en.sjtu.edu.cn/">Shanghai Jiao Tong University</a></div>
            <div class="col-2 text-center"><sup>2</sup>Alibaba</a></div>
        </div> -->
        <table align=center width="50%">
            <tr>
            <td colspan="1">
                <sup>1</sup>Shanghai Jiao Tong University
            </td>
            <td colspan="1">
                <sup>2</sup>Alibaba
            </td>
            </tr>
        </table>
      
      <h4>(CVPR 2023)</h4>

<!--         <div style="clear: both">
            <div class="paper-btn-parent">
            <a class="supp-btn" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_GANHead_Towards_Generative_Animatable_Neural_Head_Avatars_CVPR_2023_paper.pdf">
              <image src="assets/paper_icon.png" height="55px">
              <h5><strong>Paper</strong></h5>
            </a>
            <a class="supp-btn" href="https://github.com/wsj-sjtu/GANHead">
              <image src="assets/github_icon.png" height="55px">
              <h5><strong>Code</strong></h5>
            </a>
            <a class="supp-btn" href="assets/bib.txt">
                <span class="material-icons"> description </span>
                  BibTeX
            </a>
        </div></div> -->

        <table align=center width="32%">
            <tr>
            <td colspan="1">
                <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_GANHead_Towards_Generative_Animatable_Neural_Head_Avatars_CVPR_2023_paper.pdf" target="_blank">
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<image src="assets/paper_icon.png" height="55px">
                    <h5><strong>Paper</strong></h5>
                </a>
            </td>
            <td colspan="1">
                <a href="https://github.com/wsj-sjtu/GANHead" target="_blank">
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<image src="assets/github_icon.png" height="55px">
                    <h5><strong>Code</strong></h5>
                </a>
            </td>
            <td colspan="1">
                <a href="https://youtu.be/t0i10dFu7z0" target="_blank">
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<image src="assets/youtube_icon.png" height="55px">
                    <h5><strong>Video</strong></h5>
                </a>
            </td>
            </tr>
         </table>
      
    </div>

    <section id="teaser">
        <a href="assets/teaser.png">
            <img width="100%" src="assets/teaser.png">
        </a>
        <p align=center class="caption"><strong>GANHead</strong> generates animatable head avatars with complete geometry and realistic texture.
        </p>
    </section>

    <section id="abstract"/>
        <h2>Abstract</h2>
        <hr/>

        <p>To bring digital avatars into peopleâ€™s lives, it is highly demanded to efficiently generate complete, realistic, and
            animatable head avatars. This task is challenging, and it is difficult for existing methods to satisfy all the requirements
            at once. To achieve these goals, we propose GANHead (<strong>G</strong>enerative <strong>A</strong>nimatable <strong>N</strong>eural <strong>Head</strong> Avatar), 
            a novel generative head model that takes advantages of both the finegrained control over the explicit expression parameters and
            the realistic rendering results of implicit representations. Specifically, GANHead represents coarse geometry, finegained
            details and texture via three networks in canonical space to obtain the ability to generate complete and realistic
            head avatars. To achieve flexible animation, we define the deformation filed by standard linear blend skinning (LBS),
            with the learned continuous pose and expression bases and LBS weights. This allows the avatars to be directly animated 
            by FLAME parameters and generalize well to unseen poses and expressions. Compared to state-of-the-art (SOTA) methods, 
            GANHead achieves superior performance on head avatar generation and raw scan fitting.
            </p>
    </section>
    
    
    <section id="Demo Video">
        <h2>Demo Video</h2>
        <hr/>
        <figure style="width: 100%;">
            <video class="centered" width="100%" controls muted loop autoplay>
                <source src="assets/demo_new.mp4" type="video/mp4">
            </video>
            <p class="caption">The demo video shows the latent code sampling and head avatar generation results, followed by the animation results controlled by FLAME parameters.
            </p>
        </figure>
        <hr/>
    </section>
   
   
    <section id="method">
        <h2>Method</h2>
        <hr/>
        <figure style="width: 100%;">
            <a href="assets/method.png">
                <img width="100%" src="assets/method1.png">
            </a>
            <p class="caption">
            Given shape, detail and color latent codes, the canonical generation model outputs coarse geometry and detailed normal and texture in canonical space. The generated canonical head avatar can then be deformed to target pose and expression via the deformation module. In the first training stage, occupancy values of the deformed shapes are used to calculate the occupancy loss, along with the LBS loss, to supervise the geometry network and the deformation module. In the second stage, the deformed textured avatars are rendered to 2D RGB images and normal maps, together with the 3D color and normal losses, to supervise the normal and texture networks.
            </p>
        </figure>
   
    </section>
   

    <section id="Applications">
        <h2>Application</h2>
        <hr/>
        <h3>Face Reenactment</h3>
        <figure style="width: 80%;">
            <video class="centered" width="100%" controls muted loop autoplay>
                <source src="assets/reenactment.mp4" type="video/mp4">
            </video>
<!--             <p class="caption"> We estimate the FLAME parameters of the sourse video, and use the estimated pose and expression parameters to animate the generated head avatars. 
                                The generated avatars can fully reproduce FLAME's poses and expressions.
            </p> -->
        </figure>
        <p class="caption"> We estimate the FLAME parameters of the sourse video, and use the estimated pose and expression parameters to animate the generated head avatars. 
                                The generated avatars can fully reproduce FLAME's poses and expressions.
        </p>
        <br/>
        <hr/>
      
        <h3>Raw Scan Fitting</h3>
        <figure style="width: 80%;">
            <a href="assets/fitting.png">
                <img width="100%" src="assets/fitting.png">
            </a>
        </figure>
        <figure style="width: 100%;">
            <p class="caption">
                Our model can also be fitted to raw scans to produce personal animatable head avatars.
            </p>
        </figure>
    </section>

    <section id="Other Results">
        <h2>Other Results</h2>
        <hr/>
        <table align=center width="100%">
            <tr>
            <td colspan="4">
                <h3>Sample Latent Codes</h3>
            </td>
            <td colspan="5">
                <h3>Raw Scan Fitting</h3>
            </td>
            </tr>
          
            <tr>
            <td colspan="2">
                <center>
                <video width=150px controls muted loop autoplay>
                    <source src="assets/shape_code.mp4" type="video/mp4">
                </video>
            </center>
            </td>
            <td colspan="2">
                <center>
                <video width=150px controls muted loop autoplay>
                    <source src="assets/detail_code.mp4" type="video/mp4">
                </video>
                </center>
            </td>
            <td colspan="5">
                <center>
                <a href="assets/multiface_fitting.png">
                    <img width=640px src="assets/multiface_fitting.png">
                </a>
                </center>
            </td>
            </tr>
        </table>
        <p class="caption"> We also train our model on a subset of Multiface datase. Since Multiface datase has less detail and noise in the hair region, 
                            our model can learn more details of the facial region and achieve better fitting results.
        </p>
        <hr/>
    </section>

    <section class="section" id="bibtex">
      <h2>Citation</h2>
      <div style="overflow-x:auto;">
<!--         <hr/> -->
        <pre style="background-color: #e9eeef;padding: 1.25em 1.5em"><code>
@inproceedings{wu2023ganhead,
  title={GANHead: Towards Generative Animatable Neural Head Avatars},
  author={Wu, Sijing and Yan, Yichao and Li, Yunhao and Cheng, Yuhao and Zhu, Wenhan and Gao, Ke and Li, Xiaobo and Zhai, Guangtao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={437--447},
  year={2023}
}
        </code></pre>
      </div>
    </section>

    <section id="paper">
        <h2>Paper</h2>
        <hr/>
        <figure style="width: 100%;">
            <a href="https://arxiv.org/pdf/2304.03950.pdf">
                <img width="100%" src="assets/paper.png">
            </a>
        </figure>
        <hr/>
    </section>

</div>
</body>
</html>
